{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37272949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f2f452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIRS = {\n",
    "    \"train\": \"./data/train/train_splits\",\n",
    "    \"val\": \"./data/dev/dev_splits_complete\",\n",
    "    \"test\": \"./data/test/output_repeated_splits_test\"\n",
    "}\n",
    "\n",
    "OUTPUT_BASE = \"./output\"\n",
    "\n",
    "os.makedirs(OUTPUT_BASE, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b17b4e",
   "metadata": {},
   "source": [
    "## Carregamento e Transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bc1fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_seconds(t):\n",
    "    h, m, s_ms = t.split(\":\")\n",
    "    s, ms = s_ms.split(\",\")\n",
    "    return int(h)*3600 + int(m)*60 + int(s) + int(ms)/1000\n",
    "\n",
    "def to_snake_case(name: str) -> str:\n",
    "    \"\"\"Convert a string (like a column name) to snake_case.\"\"\"\n",
    "    name = name.strip()\n",
    "    name = re.sub(r\"[^\\w\\s]\", \"\", name)\n",
    "    name = re.sub(r\"\\s+\", \"_\", name)\n",
    "    return name.lower()\n",
    "\n",
    "def prepare_df(df: pd.DataFrame):\n",
    "    df[\"start_s\"] = df[\"StartTime\"].apply(to_seconds)\n",
    "    df[\"end_s\"] = df[\"EndTime\"].apply(to_seconds)\n",
    "    df[\"duration_s\"] = df[\"end_s\"] - df[\"start_s\"]\n",
    "\n",
    "    # Filter out invalid durations\n",
    "    invalid = df[df[\"duration_s\"] <= 0]\n",
    "    if len(invalid) > 0:\n",
    "        print(f\"Warning: Found {len(invalid)} rows with invalid duration, removing them.\")\n",
    "        df = df[df[\"duration_s\"] > 0]\n",
    "\n",
    "    df = df.drop(columns=[\"Sr No.\", \"StartTime\", \"EndTime\", \"Season\", \"Episode\", \"Sentiment\"])\n",
    "\n",
    "    df.columns = [to_snake_case(c) for c in df.columns]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "930e2068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found 1 rows with invalid duration, removing them.\n"
     ]
    }
   ],
   "source": [
    "train_df = prepare_df(pd.read_csv(\"./data/train_sent_emo.csv\"))\n",
    "test_df = prepare_df(pd.read_csv(\"./data/test_sent_emo.csv\"))\n",
    "val_df = prepare_df(pd.read_csv(\"./data/dev_sent_emo.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235f7e33",
   "metadata": {},
   "source": [
    "## Funções base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "75b5fd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, emotion_names, dataset_name=\"Dataset\"):\n",
    "    \"\"\"Comprehensive evaluation function for classification models.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{dataset_name} Evaluation Results\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\nOverall Accuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=emotion_names, zero_division=0))\n",
    "    \n",
    "    return acc\n",
    "\n",
    "def load_embeddings(df: pd.DataFrame, cfg: dict, normalize: bool = False):\n",
    "    \"\"\"Return concatenated embeddings (X) and numeric emotion labels (y).\n",
    "    - Tries to load all enabled modalities\n",
    "    - Automatically pads/truncates inconsistent shapes\n",
    "    - Replaces missing/corrupt embeddings with zeros\n",
    "    - Optionally normalizes features\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "\n",
    "    def safe_load(path: Path):\n",
    "        try:\n",
    "            return np.load(path)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    # ---- per‑modality handling ----\n",
    "    for mod in [\"text\", \"audio\", \"video\"]:\n",
    "        if not cfg[\"modalities\"].get(mod, {}).get(\"enabled\", False):\n",
    "            continue\n",
    "\n",
    "        emb_path = Path(cfg[\"modalities\"][mod][\"path\"])\n",
    "        feats = []\n",
    "\n",
    "        for _, r in df.iterrows():\n",
    "            arr = safe_load(emb_path / f\"{r.dialogue_id}_{r.utterance_id}.npy\")\n",
    "            feats.append(arr)\n",
    "\n",
    "        # filter missing\n",
    "        valid = [a for a in feats if a is not None]\n",
    "        if not valid:\n",
    "            raise ValueError(f\"No valid embeddings found for {mod}\")\n",
    "\n",
    "        # find a reference length (median—robust to outliers)\n",
    "        lengths = [np.prod(a.shape) for a in valid]\n",
    "        ref_len = int(np.median(lengths))\n",
    "\n",
    "        def fix_shape(a):\n",
    "            if a is None:\n",
    "                return np.zeros(ref_len)\n",
    "            flat = a.flatten()\n",
    "            if flat.size == ref_len:\n",
    "                return flat\n",
    "            elif flat.size < ref_len:\n",
    "                # pad with zeros\n",
    "                return np.pad(flat, (0, ref_len - flat.size))\n",
    "            else:\n",
    "                # truncate\n",
    "                return flat[:ref_len]\n",
    "\n",
    "        feats_fixed = [fix_shape(a) for a in feats]\n",
    "        X_list.append(np.stack(feats_fixed))\n",
    "\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No modalities enabled or loaded!\")\n",
    "\n",
    "    # concatenate along feature dimension\n",
    "    X = np.concatenate(X_list, axis=1)\n",
    "    y = df[\"emotion\"].astype(\"category\").cat.codes.to_numpy()\n",
    "\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Normalize if requested\n",
    "    if normalize:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358380b",
   "metadata": {},
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a0d52a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "\n",
      "============================================================\n",
      "Test Split Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.5125 (51.25%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.45      0.41      0.43       226\n",
      "     disgust       0.16      0.45      0.24        55\n",
      "        fear       0.07      0.27      0.11        44\n",
      "         joy       0.57      0.51      0.54       332\n",
      "     neutral       0.82      0.56      0.67       985\n",
      "     sadness       0.19      0.30      0.23       129\n",
      "    surprise       0.44      0.58      0.50       227\n",
      "\n",
      "    accuracy                           0.51      1998\n",
      "   macro avg       0.39      0.44      0.39      1998\n",
      "weighted avg       0.62      0.51      0.55      1998\n",
      "\n",
      "\n",
      "============================================================\n",
      "Validation Set Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.1389 (13.89%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.10      0.04      0.06       153\n",
      "     disgust       0.02      0.05      0.03        22\n",
      "        fear       0.03      0.42      0.06        40\n",
      "         joy       0.14      0.09      0.11       163\n",
      "     neutral       0.47      0.21      0.29       470\n",
      "     sadness       0.08      0.05      0.07       111\n",
      "    surprise       0.10      0.07      0.08       150\n",
      "\n",
      "    accuracy                           0.14      1109\n",
      "   macro avg       0.14      0.13      0.10      1109\n",
      "weighted avg       0.26      0.14      0.17      1109\n",
      "\n",
      "\n",
      "============================================================\n",
      "Summary: Test Accuracy = 0.5125, Validation Accuracy = 0.1389\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(\"configs/training/logistic.yaml\")\n",
    "\n",
    "X, y = load_embeddings(train_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=cfg[\"training\"].get(\"test_split\", 0.2), \n",
    "                                      random_state=cfg[\"training\"][\"seed\"])\n",
    "\n",
    "print(\"Training Logistic Regression...\")\n",
    "clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "clf.fit(Xtr, ytr)\n",
    "\n",
    "# Evaluate on test split\n",
    "pred_test = clf.predict(Xte)\n",
    "emotion_names = train_df[\"emotion\"].astype(\"category\").cat.categories\n",
    "test_acc = evaluate_model(yte, pred_test, emotion_names, \"Test Split\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "X_val, y_val = load_embeddings(val_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "pred_val = clf.predict(X_val)\n",
    "val_acc = evaluate_model(y_val, pred_val, val_df[\"emotion\"].astype(\"category\").cat.categories, \"Validation Set\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Summary: Test Accuracy = {test_acc:.4f}, Validation Accuracy = {val_acc:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269befaf",
   "metadata": {},
   "source": [
    "## SVM (Support Vector Machine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58fa269c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "\n",
      "============================================================\n",
      "Test Split Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.5801 (58.01%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.45      0.44      0.44       226\n",
      "     disgust       0.23      0.13      0.16        55\n",
      "        fear       0.20      0.23      0.22        44\n",
      "         joy       0.55      0.48      0.51       332\n",
      "     neutral       0.76      0.72      0.74       985\n",
      "     sadness       0.23      0.28      0.25       129\n",
      "    surprise       0.44      0.61      0.51       227\n",
      "\n",
      "    accuracy                           0.58      1998\n",
      "   macro avg       0.41      0.41      0.40      1998\n",
      "weighted avg       0.59      0.58      0.58      1998\n",
      "\n",
      "\n",
      "============================================================\n",
      "Validation Set Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.2876 (28.76%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.08      0.03      0.05       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.03      0.03      0.03        40\n",
      "         joy       0.10      0.06      0.07       163\n",
      "     neutral       0.40      0.61      0.48       470\n",
      "     sadness       0.07      0.04      0.05       111\n",
      "    surprise       0.10      0.09      0.10       150\n",
      "\n",
      "    accuracy                           0.29      1109\n",
      "   macro avg       0.11      0.12      0.11      1109\n",
      "weighted avg       0.22      0.29      0.24      1109\n",
      "\n",
      "\n",
      "============================================================\n",
      "Summary: Test Accuracy = 0.5801, Validation Accuracy = 0.2876\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "cfg = load_config(\"configs/training/svm.yaml\")\n",
    "\n",
    "X, y = load_embeddings(train_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=cfg[\"training\"][\"test_split\"], \n",
    "                                      random_state=cfg[\"training\"][\"seed\"])\n",
    "\n",
    "clf = SVC(\n",
    "    kernel=cfg[\"model\"][\"kernel\"],\n",
    "    C=cfg[\"model\"][\"C\"],\n",
    "    gamma=cfg[\"model\"][\"gamma\"],\n",
    "    class_weight=cfg[\"model\"][\"class_weight\"],\n",
    "    random_state=cfg[\"training\"][\"seed\"]\n",
    ")\n",
    "\n",
    "print(\"Training SVM...\")\n",
    "clf.fit(Xtr, ytr)\n",
    "\n",
    "# Evaluate on test split\n",
    "pred_test = clf.predict(Xte)\n",
    "emotion_names = train_df[\"emotion\"].astype(\"category\").cat.categories\n",
    "test_acc = evaluate_model(yte, pred_test, emotion_names, \"Test Split\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "X_val, y_val = load_embeddings(val_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "pred_val = clf.predict(X_val)\n",
    "val_acc = evaluate_model(y_val, pred_val, val_df[\"emotion\"].astype(\"category\").cat.categories, \"Validation Set\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Summary: Test Accuracy = {test_acc:.4f}, Validation Accuracy = {val_acc:.4f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e7ef3",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "812677de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "\n",
      "============================================================\n",
      "Test Split Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.6026 (60.26%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.48      0.26      0.34       226\n",
      "     disgust       0.00      0.00      0.00        55\n",
      "        fear       0.00      0.00      0.00        44\n",
      "         joy       0.49      0.36      0.41       332\n",
      "     neutral       0.63      0.95      0.75       985\n",
      "     sadness       1.00      0.02      0.03       129\n",
      "    surprise       0.64      0.40      0.49       227\n",
      "\n",
      "    accuracy                           0.60      1998\n",
      "   macro avg       0.46      0.28      0.29      1998\n",
      "weighted avg       0.58      0.60      0.54      1998\n",
      "\n",
      "\n",
      "============================================================\n",
      "Validation Set Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.3255 (32.55%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.11      0.05      0.06       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.05      0.03      0.03        40\n",
      "         joy       0.12      0.08      0.10       163\n",
      "     neutral       0.41      0.70      0.52       470\n",
      "     sadness       0.10      0.03      0.04       111\n",
      "    surprise       0.12      0.06      0.08       150\n",
      "\n",
      "    accuracy                           0.33      1109\n",
      "   macro avg       0.13      0.13      0.12      1109\n",
      "weighted avg       0.24      0.33      0.26      1109\n",
      "\n",
      "\n",
      "============================================================\n",
      "Summary: Test Accuracy = 0.6026, Validation Accuracy = 0.3255\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "cfg = load_config(\"configs/training/random_forest.yaml\")\n",
    "\n",
    "X, y = load_embeddings(train_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=cfg[\"training\"][\"test_split\"], \n",
    "                                      random_state=cfg[\"training\"][\"seed\"])\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=cfg[\"model\"][\"n_estimators\"],\n",
    "    max_depth=cfg[\"model\"][\"max_depth\"],\n",
    "    min_samples_split=cfg[\"model\"][\"min_samples_split\"],\n",
    "    min_samples_leaf=cfg[\"model\"][\"min_samples_leaf\"],\n",
    "    class_weight=cfg[\"model\"][\"class_weight\"],\n",
    "    max_features=cfg[\"model\"][\"max_features\"],\n",
    "    random_state=cfg[\"training\"][\"seed\"],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "clf.fit(Xtr, ytr)\n",
    "\n",
    "# Evaluate on test split\n",
    "pred_test = clf.predict(Xte)\n",
    "emotion_names = train_df[\"emotion\"].astype(\"category\").cat.categories\n",
    "test_acc = evaluate_model(yte, pred_test, emotion_names, \"Test Split\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "X_val, y_val = load_embeddings(val_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "pred_val = clf.predict(X_val)\n",
    "val_acc = evaluate_model(y_val, pred_val, val_df[\"emotion\"].astype(\"category\").cat.categories, \"Validation Set\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Summary: Test Accuracy = {test_acc:.4f}, Validation Accuracy = {val_acc:.4f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f287ed",
   "metadata": {},
   "source": [
    "## Deep MLP (Multi-layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6572a4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deep MLP...\n",
      "Epoch 1/100 - val acc: 0.586, loss: 1.4446\n",
      "Epoch 2/100 - val acc: 0.625, loss: 1.2676\n",
      "Epoch 3/100 - val acc: 0.618, loss: 1.2112\n",
      "Epoch 4/100 - val acc: 0.625, loss: 1.1661\n",
      "Epoch 5/100 - val acc: 0.629, loss: 1.1282\n",
      "Epoch 6/100 - val acc: 0.633, loss: 1.1092\n",
      "Epoch 7/100 - val acc: 0.628, loss: 1.0764\n",
      "Epoch 8/100 - val acc: 0.639, loss: 1.0557\n",
      "Epoch 9/100 - val acc: 0.626, loss: 1.0415\n",
      "Epoch 10/100 - val acc: 0.625, loss: 1.0072\n",
      "Epoch 11/100 - val acc: 0.632, loss: 0.9857\n",
      "Epoch 12/100 - val acc: 0.624, loss: 0.9613\n",
      "Epoch 13/100 - val acc: 0.620, loss: 0.9334\n",
      "Epoch 14/100 - val acc: 0.615, loss: 0.9136\n",
      "Epoch 15/100 - val acc: 0.612, loss: 0.8787\n",
      "Epoch 16/100 - val acc: 0.601, loss: 0.8591\n",
      "Epoch 17/100 - val acc: 0.606, loss: 0.8302\n",
      "Epoch 18/100 - val acc: 0.607, loss: 0.8031\n",
      "Early stopping at epoch 18\n",
      "\n",
      "============================================================\n",
      "Test Split Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.6071 (60.71%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.41      0.38      0.40       226\n",
      "     disgust       0.28      0.09      0.14        55\n",
      "        fear       0.26      0.20      0.23        44\n",
      "         joy       0.52      0.46      0.49       332\n",
      "     neutral       0.72      0.82      0.77       985\n",
      "     sadness       0.27      0.19      0.22       129\n",
      "    surprise       0.54      0.54      0.54       227\n",
      "\n",
      "    accuracy                           0.61      1998\n",
      "   macro avg       0.43      0.38      0.40      1998\n",
      "weighted avg       0.58      0.61      0.59      1998\n",
      "\n",
      "\n",
      "============================================================\n",
      "Validation Set Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.2290 (22.90%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.09      0.03      0.04       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.03      0.03      0.03        40\n",
      "         joy       0.15      0.45      0.22       163\n",
      "     neutral       0.45      0.33      0.38       470\n",
      "     sadness       0.08      0.03      0.04       111\n",
      "    surprise       0.11      0.11      0.11       150\n",
      "\n",
      "    accuracy                           0.23      1109\n",
      "   macro avg       0.13      0.14      0.12      1109\n",
      "weighted avg       0.25      0.23      0.22      1109\n",
      "\n",
      "\n",
      "============================================================\n",
      "Summary: Test Accuracy = 0.6071, Validation Accuracy = 0.2290\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "class DeepMLPClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_sizes, out_dim, dropout=0.3, batch_norm=False):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_size = in_dim\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(prev_size, out_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_deep_mlp(X, y, cfg):\n",
    "    torch.manual_seed(cfg[\"training\"][\"seed\"])\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=cfg[\"training\"][\"test_split\"],\n",
    "                                          random_state=cfg[\"training\"][\"seed\"])\n",
    "\n",
    "    Xtr_t = torch.tensor(Xtr, dtype=torch.float32)\n",
    "    ytr_t = torch.tensor(ytr, dtype=torch.long)\n",
    "    Xte_t = torch.tensor(Xte, dtype=torch.float32)\n",
    "    yte_t = torch.tensor(yte, dtype=torch.long)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(Xtr_t, ytr_t),\n",
    "                              batch_size=cfg[\"training\"][\"batch_size\"],\n",
    "                              shuffle=True)\n",
    "\n",
    "    model = DeepMLPClassifier(\n",
    "        in_dim=X.shape[1],\n",
    "        hidden_sizes=cfg[\"model\"][\"hidden_sizes\"],\n",
    "        out_dim=len(np.unique(y)),\n",
    "        dropout=cfg[\"model\"][\"dropout\"],\n",
    "        batch_norm=cfg[\"model\"].get(\"batch_norm\", False)\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=float(cfg[\"training\"][\"learning_rate\"]))\n",
    "\n",
    "    best_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    patience = cfg[\"training\"].get(\"patience\", None)\n",
    "    early_stopping = cfg[\"training\"].get(\"early_stopping\", False)\n",
    "\n",
    "    for epoch in range(cfg[\"training\"][\"epochs\"]):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            optim.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 or early_stopping:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                preds = model(Xte_t).argmax(dim=1)\n",
    "                acc = (preds == yte_t).float().mean().item()\n",
    "                print(f\"Epoch {epoch+1}/{cfg['training']['epochs']} - val acc: {acc:.3f}, loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "            \n",
    "            if early_stopping:\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "cfg = load_config(\"configs/training/deep_mlp.yaml\")\n",
    "X, y = load_embeddings(train_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "\n",
    "print(\"Training Deep MLP...\")\n",
    "# Store test split for evaluation\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=cfg[\"training\"][\"test_split\"],\n",
    "                                      random_state=cfg[\"training\"][\"seed\"])\n",
    "deep_mlp = train_deep_mlp(X, y, cfg)\n",
    "\n",
    "# Evaluate on test split\n",
    "Xte_t = torch.tensor(Xte, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    pred_test = deep_mlp(Xte_t).argmax(dim=1).numpy()\n",
    "emotion_names = train_df[\"emotion\"].astype(\"category\").cat.categories\n",
    "test_acc = evaluate_model(yte, pred_test, emotion_names, \"Test Split\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "X_val, y_val = load_embeddings(val_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    pred_val = deep_mlp(X_val_t).argmax(dim=1).numpy()\n",
    "val_acc = evaluate_model(y_val, pred_val, val_df[\"emotion\"].astype(\"category\").cat.categories, \"Validation Set\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Summary: Test Accuracy = {test_acc:.4f}, Validation Accuracy = {val_acc:.4f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5c6c3",
   "metadata": {},
   "source": [
    "## Multimodal MLP (All Modalities Combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cba3a3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dimension: 1536\n",
      "Number of samples: 9989\n",
      "Number of classes: 7\n",
      "\n",
      "Training Multimodal MLP...\n",
      "Epoch 1/100 - val acc: 0.619, loss: 1.3605\n",
      "Epoch 2/100 - val acc: 0.613, loss: 1.1515\n",
      "Epoch 3/100 - val acc: 0.615, loss: 1.0788\n",
      "Epoch 4/100 - val acc: 0.609, loss: 1.0139\n",
      "Epoch 5/100 - val acc: 0.607, loss: 0.9641\n",
      "Epoch 6/100 - val acc: 0.604, loss: 0.9235\n",
      "Epoch 7/100 - val acc: 0.593, loss: 0.8824\n",
      "Epoch 8/100 - val acc: 0.568, loss: 0.8198\n",
      "Epoch 9/100 - val acc: 0.584, loss: 0.7839\n",
      "Epoch 10/100 - val acc: 0.593, loss: 0.7100\n",
      "Epoch 11/100 - val acc: 0.556, loss: 0.6823\n",
      "Early stopping at epoch 11\n",
      "\n",
      "============================================================\n",
      "Test Split Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.5556 (55.56%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.32      0.27      0.29       226\n",
      "     disgust       0.22      0.15      0.18        55\n",
      "        fear       0.21      0.14      0.17        44\n",
      "         joy       0.42      0.47      0.44       332\n",
      "     neutral       0.73      0.75      0.74       985\n",
      "     sadness       0.25      0.20      0.22       129\n",
      "    surprise       0.44      0.52      0.48       227\n",
      "\n",
      "    accuracy                           0.56      1998\n",
      "   macro avg       0.37      0.36      0.36      1998\n",
      "weighted avg       0.54      0.56      0.55      1998\n",
      "\n",
      "\n",
      "============================================================\n",
      "Validation Set Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.3003 (30.03%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.10      0.05      0.07       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.07      0.03      0.04        40\n",
      "         joy       0.12      0.06      0.08       163\n",
      "     neutral       0.40      0.63      0.49       470\n",
      "     sadness       0.07      0.02      0.03       111\n",
      "    surprise       0.11      0.13      0.12       150\n",
      "\n",
      "    accuracy                           0.30      1109\n",
      "   macro avg       0.12      0.13      0.12      1109\n",
      "weighted avg       0.23      0.30      0.25      1109\n",
      "\n",
      "\n",
      "============================================================\n",
      "Summary: Test Accuracy = 0.5556, Validation Accuracy = 0.3003\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(\"configs/training/multimodal.yaml\")\n",
    "X, y = load_embeddings(train_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "\n",
    "print(f\"Feature dimension: {X.shape[1]}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "\n",
    "print(\"\\nTraining Multimodal MLP...\")\n",
    "# Store test split for evaluation\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=cfg[\"training\"][\"test_split\"],\n",
    "                                      random_state=cfg[\"training\"][\"seed\"])\n",
    "multimodal_mlp = train_mlp(X, y, cfg)\n",
    "\n",
    "# Evaluate on test split\n",
    "Xte_t = torch.tensor(Xte, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    pred_test = multimodal_mlp(Xte_t).argmax(dim=1).numpy()\n",
    "emotion_names = train_df[\"emotion\"].astype(\"category\").cat.categories\n",
    "test_acc = evaluate_model(yte, pred_test, emotion_names, \"Test Split\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "X_val, y_val = load_embeddings(val_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    pred_val = multimodal_mlp(X_val_t).argmax(dim=1).numpy()\n",
    "val_acc = evaluate_model(y_val, pred_val, val_df[\"emotion\"].astype(\"category\").cat.categories, \"Validation Set\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Summary: Test Accuracy = {test_acc:.4f}, Validation Accuracy = {val_acc:.4f}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825f1603",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6d170d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, hidden, out_dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d797f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(X, y, cfg):\n",
    "    torch.manual_seed(cfg[\"training\"][\"seed\"])\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=cfg[\"training\"][\"test_split\"],\n",
    "                                          random_state=cfg[\"training\"][\"seed\"])\n",
    "\n",
    "    Xtr_t = torch.tensor(Xtr, dtype=torch.float32)\n",
    "    ytr_t = torch.tensor(ytr, dtype=torch.long)\n",
    "    Xte_t = torch.tensor(Xte, dtype=torch.float32)\n",
    "    yte_t = torch.tensor(yte, dtype=torch.long)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(Xtr_t, ytr_t),\n",
    "                              batch_size=cfg[\"training\"][\"batch_size\"],\n",
    "                              shuffle=True)\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        in_dim=X.shape[1],\n",
    "        hidden=cfg[\"model\"][\"hidden_size\"],\n",
    "        out_dim=len(np.unique(y)),\n",
    "        dropout=cfg[\"model\"][\"dropout\"]\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=float(cfg[\"training\"][\"learning_rate\"]))\n",
    "\n",
    "    best_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    patience = cfg[\"training\"].get(\"patience\", None)\n",
    "    early_stopping = cfg[\"training\"].get(\"early_stopping\", False)\n",
    "\n",
    "    for epoch in range(cfg[\"training\"][\"epochs\"]):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            optim.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 or early_stopping:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                preds = model(Xte_t).argmax(dim=1)\n",
    "                acc = (preds == yte_t).float().mean().item()\n",
    "                print(f\"Epoch {epoch+1}/{cfg['training']['epochs']} - val acc: {acc:.3f}, loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "            \n",
    "            if early_stopping:\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                        break\n",
    "\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "319a5115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP...\n",
      "Epoch 5/50 - val acc: 0.591, loss: 1.2179\n",
      "Epoch 10/50 - val acc: 0.629, loss: 1.1428\n",
      "Epoch 15/50 - val acc: 0.632, loss: 1.1064\n",
      "Epoch 20/50 - val acc: 0.606, loss: 1.0687\n",
      "Epoch 25/50 - val acc: 0.629, loss: 1.0452\n",
      "Epoch 30/50 - val acc: 0.635, loss: 1.0075\n",
      "Epoch 35/50 - val acc: 0.634, loss: 0.9800\n",
      "Epoch 40/50 - val acc: 0.627, loss: 0.9405\n",
      "Epoch 45/50 - val acc: 0.627, loss: 0.9100\n",
      "Epoch 50/50 - val acc: 0.626, loss: 0.8806\n",
      "\n",
      "============================================================\n",
      "Test Split Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.6256 (62.56%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.49      0.39      0.43       226\n",
      "     disgust       0.30      0.05      0.09        55\n",
      "        fear       0.40      0.05      0.08        44\n",
      "         joy       0.56      0.46      0.50       332\n",
      "     neutral       0.72      0.87      0.79       985\n",
      "     sadness       0.28      0.16      0.20       129\n",
      "    surprise       0.48      0.58      0.52       227\n",
      "\n",
      "    accuracy                           0.63      1998\n",
      "   macro avg       0.46      0.36      0.37      1998\n",
      "weighted avg       0.59      0.63      0.60      1998\n",
      "\n",
      "\n",
      "============================================================\n",
      "Validation Set Evaluation Results\n",
      "============================================================\n",
      "\n",
      "Overall Accuracy: 0.3192 (31.92%)\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.05      0.02      0.03       153\n",
      "     disgust       0.00      0.00      0.00        22\n",
      "        fear       0.00      0.00      0.00        40\n",
      "         joy       0.13      0.08      0.10       163\n",
      "     neutral       0.40      0.69      0.51       470\n",
      "     sadness       0.08      0.02      0.03       111\n",
      "    surprise       0.11      0.07      0.09       150\n",
      "\n",
      "    accuracy                           0.32      1109\n",
      "   macro avg       0.11      0.13      0.11      1109\n",
      "weighted avg       0.22      0.32      0.25      1109\n",
      "\n",
      "\n",
      "============================================================\n",
      "Summary: Test Accuracy = 0.6256, Validation Accuracy = 0.3192\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(\"./configs/training/mlp.yaml\")\n",
    "X, y = load_embeddings(train_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "\n",
    "print(\"Training MLP...\")\n",
    "# Store test split for evaluation\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=cfg[\"training\"][\"test_split\"],\n",
    "                                      random_state=cfg[\"training\"][\"seed\"])\n",
    "clf = train_mlp(X, y, cfg)\n",
    "\n",
    "# Evaluate on test split\n",
    "Xte_t = torch.tensor(Xte, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    pred_test = clf(Xte_t).argmax(dim=1).numpy()\n",
    "emotion_names = train_df[\"emotion\"].astype(\"category\").cat.categories\n",
    "test_acc = evaluate_model(yte, pred_test, emotion_names, \"Test Split\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "X_val, y_val = load_embeddings(val_df, cfg, normalize=cfg[\"training\"].get(\"normalize\", False))\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "with torch.no_grad():\n",
    "    pred_val = clf(X_val_t).argmax(dim=1).numpy()\n",
    "val_acc = evaluate_model(y_val, pred_val, val_df[\"emotion\"].astype(\"category\").cat.categories, \"Validation Set\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Summary: Test Accuracy = {test_acc:.4f}, Validation Accuracy = {val_acc:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
