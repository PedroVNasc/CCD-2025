{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1339749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cf_matrix_df):\n",
    "\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "    z=cf_matrix_df.values,\n",
    "    x=cf_matrix_df.columns,\n",
    "    y=cf_matrix_df.index,\n",
    "    colorscale='Viridis',\n",
    "    colorbar=dict(title='Count'),\n",
    "    zmin=0,\n",
    "    zmax=cf_matrix_df.values.max(),\n",
    "    hoverongaps=False\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='Confusion Matrix',\n",
    "        xaxis=dict(title='Predicted Label'),\n",
    "        yaxis=dict(title='True Label', autorange='reversed'),\n",
    "        width=800,\n",
    "        height=800\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546033a",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e77022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" train_df = pd.read_json(\"../data/C2/train.json\")\n",
    "train_df\n",
    "\n",
    "cuisine_embeddings = {}\n",
    "for cuisine in train_df[\"cuisine\"].unique().tolist():\n",
    "    cuisine_embeddings[cuisine] = list(model.encode(f\"{cuisine} cuisine\")) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33967f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_matching_cuisine(cuisine_embeddings, ingredient_list):\n",
    "    ingredient_embedding = model.encode(\"A cuisine with dishes that uses ingredients such as: \" + \" \".join(ingredient_list))\n",
    "\n",
    "    similarity_dict = {}\n",
    "    for cuisine, embedding in cuisine_embeddings.items():\n",
    "        similarity_dict[cuisine] = util.cos_sim(ingredient_embedding, embedding)[0]\n",
    "    \n",
    "    return max(similarity_dict, key=similarity_dict.get)\n",
    "\n",
    "def make_predictions_df(df, cuisine_embeddings):\n",
    "\n",
    "    rows = df.to_dict(orient=\"records\")\n",
    "\n",
    "    for i in tqdm(range(len(rows))):\n",
    "        rows[i][\"predicted_cuisine\"] = find_best_matching_cuisine(cuisine_embeddings, rows[i][\"ingredients\"])\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3312eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_df = make_predictions_df(train_df, cuisine_embeddings)\n",
    "#predictions_df.to_csv(\"../data/C2/cos_similarity_predictions.csv\", index=False)\n",
    "predictions_df = pd.read_csv(\"../data/C2/cos_similarity_predictions.csv\")\n",
    "predictions_df['ingredients'] = predictions_df['ingredients'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083539a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df[\"predicted_cuisine\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictions_df['cuisine'], predictions_df['predicted_cuisine'], target_names=predictions_df['cuisine'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b58b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity_cm = confusion_matrix(predictions_df['cuisine'], predictions_df['predicted_cuisine'], labels=predictions_df['cuisine'].unique(), normalize='true')\n",
    "\n",
    "cm_df = pd.DataFrame(cos_similarity_cm, \n",
    "                     index=[f\"{cuisine}\" for cuisine in predictions_df['cuisine'].unique()],\n",
    "                     columns=[f\"{cuisine}\" for cuisine in predictions_df['cuisine'].unique()])\n",
    "\n",
    "plot_confusion_matrix(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a34f29f",
   "metadata": {},
   "source": [
    "### Cajun Creole Arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_df.to_csv(\"../data/C2/cajun_creole_prediction.csv\")\n",
    "predictions_df = pd.read_csv(\"../data/C2/cajun_creole_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8865207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686ec12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_points(sampled_values):\n",
    "    cuisines = [item[\"cuisine\"] for item in sampled_values]\n",
    "    ingredients = [\"A cuisine with dishes that uses ingredients such as: \" + \" \".join(item[\"ingredients\"]) for item in sampled_values]\n",
    "\n",
    "    embeddings = list(model.encode(cuisines)) + list(model.encode(ingredients))\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    cuisine_points = reduced_embeddings[:len(cuisines)]\n",
    "    ingredient_points = reduced_embeddings[len(cuisines):]\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=cuisine_points[:, 0], y=cuisine_points[:, 1],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=15, color='blue', symbol='circle'),\n",
    "        text=cuisines,\n",
    "        textposition='top center',\n",
    "        name='Cuisines'\n",
    "    ))\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=ingredient_points[:, 0], y=ingredient_points[:, 1],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=12, color='red', symbol='diamond'),\n",
    "        text=[f\"Ingredients for {cuisine}\" for cuisine in cuisines],\n",
    "        textposition='bottom center',\n",
    "        name='Ingredients'\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Semantic Embedding Visualization\",\n",
    "        xaxis_title=\"PCA Component 1\",\n",
    "        yaxis_title=\"PCA Component 2\",\n",
    "        width=700,\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11907651",
   "metadata": {},
   "outputs": [],
   "source": [
    "creoles = predictions_df.query(\"cuisine == 'cajun_creole'\").head(3).to_dict(orient=\"records\")\n",
    "sampled_values = predictions_df.head(10).to_dict(orient=\"records\")\n",
    "\n",
    "sampled_values.extend(creoles)\n",
    "\n",
    "cajun_creole_embedding = model.encode(\"cajun_creole\")\n",
    "for value in sampled_values:\n",
    "    cuisine_embedding = model.encode(value[\"cuisine\"])\n",
    "    ingredients_embedding = model.encode(\"A cuisine with dishes that uses ingredients such as: \" + \" \".join(value[\"ingredients\"]))\n",
    "    print(f\"Cosine Similarity for {value[\"cuisine\"]}: {util.cos_sim(cuisine_embedding, ingredients_embedding)} vs for cajun_creole: {util.cos_sim(cajun_creole_embedding,ingredients_embedding)}\")\n",
    "\n",
    "plot_embedding_points(sampled_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff2463",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df[\"predicted_cuisine\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014ee322",
   "metadata": {},
   "source": [
    "## Training-Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de2c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" rows = pd.read_json(\"../data/C2/train.json\").to_dict(orient=\"records\")\n",
    "for row in tqdm(rows):\n",
    "    embedding = model.encode(\" \".join(row[\"ingredients\"]))\n",
    "    row[\"embedded_ingredients\"] = json.dumps(embedding.tolist())\n",
    "\n",
    "pd.DataFrame(rows).to_csv(\"../data/C2/train_with_embeddings.csv\")\n",
    "\n",
    "rows = pd.read_json(\"../data/C2/test.json\").to_dict(orient=\"records\")\n",
    "for row in tqdm(rows):\n",
    "    embedding = model.encode(\" \".join(row[\"ingredients\"]))\n",
    "    row[\"embedded_ingredients\"] = json.dumps(embedding.tolist())\n",
    "\n",
    "pd.DataFrame(rows).to_csv(\"../data/C2/test_with_embeddings.csv\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af333b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_with_embeddings = pd.read_csv(\"../data/C2/train_with_embeddings.csv\")\n",
    "train_df_with_embeddings['embedded_ingredients'] = train_df_with_embeddings['embedded_ingredients'].apply(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded466ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(df, model=1, random_state=None):\n",
    "    X = np.vstack(df['embedded_ingredients'].values)\n",
    "    y = df[\"cuisine\"].tolist()\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=random_state, stratify=y)\n",
    "    \n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    if model == 1:\n",
    "        clf = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n",
    "    elif model == 2:\n",
    "        clf = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=random_state)\n",
    "    elif model == 3:\n",
    "        clf = xgb.XGBClassifier(\n",
    "                objective='multi:softmax',\n",
    "                num_class=len(label_encoder.classes_),\n",
    "                eval_metric='mlogloss',\n",
    "                max_depth=6,\n",
    "                n_estimators=100,\n",
    "                random_state=random_state\n",
    "            )    \n",
    "    else:\n",
    "        clf = lgb.LGBMClassifier(\n",
    "            objective='multiclass',\n",
    "            num_class=len(label_encoder.classes_),\n",
    "            learning_rate=0.1,\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            random_state=random_state,\n",
    "            verbose=-1\n",
    "        )\n",
    "    \n",
    "    clf.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    cf_matrix_df = pd.DataFrame(confusion_matrix(y_test, y_pred, normalize='true'), index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "\n",
    "    return cf_matrix_df, classification_report(y_test, y_pred, target_names=label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59141ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_cf, logistic_regression_report = evaluate_predictions(train_df_with_embeddings, model=1)\n",
    "print(logistic_regression_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(logistic_regression_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_cf, random_forest_report = evaluate_predictions(train_df_with_embeddings, model=2)\n",
    "print(random_forest_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4099651",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(random_forest_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f10a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_cf, xgboost_report = evaluate_predictions(train_df_with_embeddings, model=3)\n",
    "print(xgboost_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(xgboost_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa263c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_cf, lightgbm_report = evaluate_predictions(train_df_with_embeddings, model=4)\n",
    "print(lightgbm_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e02211",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(lightgbm_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d41d90d",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/C2/train.json\")\n",
    "ingredients_set = set().union(*df[\"ingredients\"])\n",
    "len(ingredients_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(util.cos_sim(model.encode(\"chopped onion\"), model.encode(\"onion\")))\n",
    "print(util.cos_sim(model.encode(\"onion soup\"), model.encode(\"onion\")))\n",
    "print(util.cos_sim(model.encode(\"whole milk\"), model.encode(\"milk\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ingredient_encoding = {}\n",
    "for ingredient in tqdm(ingredients_set):\n",
    "    ingredient_encoding[ingredient] = np.array(model.encode(ingredient).tolist()) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ae452",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ingredient_substitution = {}\n",
    "\n",
    "ingredients = list(ingredients_set)\n",
    "for i in tqdm(range(len(ingredients))):\n",
    "\n",
    "    if ingredients[i] not in ingredients_set:\n",
    "        continue\n",
    "\n",
    "    ingredient_substitution[ingredients[i]] = [ingredients[i]]\n",
    "\n",
    "    for j in range(i+1, len(ingredients)):\n",
    "        if util.cos_sim(ingredient_encoding[ingredients[i]], ingredient_encoding[ingredients[j]]) > 0.79:\n",
    "            ingredient_substitution[ingredients[i]].append(ingredients[j])\n",
    "\n",
    "            ingredients_set.discard(ingredients[j]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" with open(\"../data/C2/ingredient_sub.json\", \"w\") as file:\n",
    "    json.dump(ingredient_substitution, file) \"\"\"\n",
    "\n",
    "with open(\"../data/C2/ingredient_sub.json\", 'r') as file:\n",
    "    ingredient_substitution = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc81f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ingredient_substitution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b731f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_map = {v: k for k, vals in ingredient_substitution.items() for v in vals}\n",
    "df[\"ingredients\"] = df['ingredients'].apply(lambda lst: [reverse_map.get(item, item) for item in lst])\n",
    "df[\"ingredients\"] = df['ingredients'].apply(lambda lst: [re.sub(r'\\s{2,}', '_', token.strip()) for token in lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b331825",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['cuisine'])\n",
    "\n",
    "\n",
    "cuisine_documents = train_df.groupby('cuisine')['ingredients'].apply(\n",
    "    lambda lists: ' '.join([token for sublist in lists for token in sublist])\n",
    ")\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(cuisine_documents)\n",
    "\n",
    "train_tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    index=cuisine_documents.index,\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ingredients(ingredient_list, vectorizer, tfidf_matrix, label_index, ingredient_substitution):\n",
    "    reverse_map = {v: k for k, vals in ingredient_substitution.items() for v in vals}\n",
    "\n",
    "    # Preprocess tokens: replace whitespace with underscores\n",
    "    cleaned_tokens = [reverse_map.get(item, item) for item in ingredient_list]\n",
    "    cleaned_tokens = [re.sub(r'\\s+', '_', token.strip()) for token in ingredient_list]\n",
    "\n",
    "    doc = ' '.join(cleaned_tokens)\n",
    "    doc_vector = vectorizer.transform([doc])\n",
    "\n",
    "    similarities = cosine_similarity(doc_vector, tfidf_matrix)\n",
    "\n",
    "    best_label_idx = similarities.argmax()\n",
    "    best_label = label_index[best_label_idx]\n",
    "\n",
    "    return best_label, similarities[0][best_label_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122bc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index = cuisine_documents.index\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "rows = test_df.to_dict(orient=\"records\")\n",
    "for i in range(len(rows)):\n",
    "    pred_label, _ = classify_ingredients(rows[i]['ingredients'], vectorizer, tfidf_matrix, label_index, ingredient_substitution)\n",
    "    rows[i]['predicted_cuisine'] = pred_label\n",
    "\n",
    "predictions_df = pd.DataFrame(rows)\n",
    "print(classification_report(predictions_df['cuisine'], predictions_df['predicted_cuisine'], target_names=predictions_df['cuisine'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106edcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(rows)\n",
    "cos_similarity_cm = confusion_matrix(predictions_df['cuisine'], predictions_df['predicted_cuisine'], labels=predictions_df['cuisine'].unique(), normalize='true')\n",
    "\n",
    "cm_df = pd.DataFrame(cos_similarity_cm, \n",
    "                     index=[f\"{cuisine}\" for cuisine in predictions_df['cuisine'].unique()],\n",
    "                     columns=[f\"{cuisine}\" for cuisine in predictions_df['cuisine'].unique()])\n",
    "\n",
    "plot_confusion_matrix(cm_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
